spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
spring.http.encoding.force=true
server.port=8090
spring.application.name=springboot
spring.mvc.servlet.path=/springboot

# data source 
spring.datasource.druid.url=jdbc:mysql://10.166.10.110:3306/folink?useSSL=false&serverTimezone=Asia/Shanghai
spring.datasource.druid.username=money
spring.datasource.druid.password=money
spring.datasource.druid.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.druid.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.druid.initial-size=20
spring.datasource.druid.max-active=300
spring.datasource.druid.min-idle=20
spring.datasource.druid.max-wait=60000
spring.datasource.druid.pool-prepared-statements=true
spring.datasource.druid.max-pool-prepared-statement-per-connection-size=20
spring.datasource.druid.validation-query=select 1 from dual
spring.datasource.druid.test-on-borrow=false
spring.datasource.druid.test-on-return=false
spring.datasource.druid.test-while-idle=true
spring.datasource.druid.time-between-eviction-runs-millis=60000
spring.datasource.druid.min-evictable-idle-time-millis=300000
spring.datasource.druid.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
spring.datasource.druid.filters=stat,wall,slf4j
spring.datasource.druid.stat-view-servlet.enabled=true
spring.datasource.druid.stat-view-servlet.url-pattern=/druid/*
spring.datasource.druid.stat-view-servlet.reset-enable=false

# mybatis
mybatis.mapper-locations=classpath*:mapper/*.xml
mybatis.configuration.map-underscore-to-camel-case=true

# Kafka/ZK config

# UAT Env
#broker.servers=10.166.10.243:9092,10.166.10.244:9092,10.166.10.245:9092
#zookeeper.servers=10.166.10.243:2181,10.166.10.243:2181,10.166.10.245:2181
#kafka.topic=flink

# Kafka Test Env
broker.servers=10.166.10.110:9092,10.166.10.110:9092,10.166.10.110:9092
zookeeper.servers=10.166.10.110:2181,10.166.10.110:2181,10.166.10.110:2181
kafka.topic=test

kafka.group.id=flink-group


#config source database
source.database.list=iccs_ca,iccs_ex


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=10.166.10.110:9092,10.166.10.110:9092,10.166.10.110:9092

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-consumer-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#apollo config
apollo.meta=http://10.166.8.140:18080
apollo.cacheDir=/opt/data/some-cache-dir